{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2674e289-cc8d-4452-8581-dc1ae337b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import shapely\n",
    "#import cftime\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as cx\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4793cc25-f186-4a54-acfb-43b675fc17d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'GEO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4953d7d0-74ea-4c82-a3a5-92405793d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_data_path = Path(pathlib.Path.home().parts[0]) / 'Projects' / 'gmhcira' / 'data' / 'damage' / country\n",
    "eq_damage_data_path = damage_data_path / 'landslide_eq'\n",
    "his_rainfall_damage_data_path = damage_data_path / 'landslide_rf_historical'\n",
    "fut126_rainfall_damage_data_path = damage_data_path / 'landslide_rf_ssp126'\n",
    "fut585_rainfall_damage_data_path = damage_data_path / 'landslide_rf_ssp585'\n",
    "\n",
    "admin_path = Path('C:\\\\Users/snn490/OneDrive - Vrije Universiteit Amsterdam\\WorldBank_Projects\\SupplyChainECA\\data\\gadm')\n",
    "figures_path = Path('C://Users/snn490/OneDrive - Vrije Universiteit Amsterdam/WorldBank_Projects/SupplyChainECA/asset_damages/{}/landslides_figures'.format(country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72670bf3-a310-4858-a201-3a30e211b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def calculate_risk(road_segment, damages_dict):\n",
    "#    damages_lst = [damages_dict[rp][damages_dict[rp]['osm_id'] == road_segment]['Partial destruction (0.5)'].iloc[0] for rp in [*damages_dict]]\n",
    "#    asset_dam_df = pd.DataFrame([1/rp for rp in [*damages_dict]]+[1,1e-10],damages_lst+[0, max(damages_lst)]).reset_index()\n",
    "#    asset_dam_df.columns = ['damage','prob']\n",
    "#    asset_dam_df = asset_dam_df.sort_values('prob',ascending=True).reset_index(drop=True)\n",
    "#    return np.trapz(asset_dam_df.damage.values,asset_dam_df.prob.values) #np.trapz(y,x)\n",
    "\n",
    "def calculate_risk_vectorized(row):\n",
    "    damages_lst = row.values\n",
    "    rps = row.index\n",
    "    if isinstance((row.index)[0], str): rps = [int(s) for con_rp in rps for s in re.findall(r'\\d+', con_rp)]\n",
    "    prob_values = np.array([1/rp for rp in rps] + [1, 1e-10]) #without design standard of rp 10\n",
    "    damage_values = np.append(damages_lst, [0, max(damages_lst)])\n",
    "    sorted_indices = np.argsort(prob_values)\n",
    "    prob_values = prob_values[sorted_indices]\n",
    "    damage_values = damage_values[sorted_indices]\n",
    "    return np.trapz(damage_values, prob_values)\n",
    "\n",
    "def get_province(road_segment,subnational):\n",
    "    try:\n",
    "        return subnational.loc[road_segment.geometry.intersects(subnational.geometry)].GID_3.values[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def handle_zero_values(ead_df, haz_trig_rp_lst):\n",
    "    \"\"\"\n",
    "    Replaces zero values in higher return periods with the value of the previous lower return period,\n",
    "    if the lower return period has a non-zero value.\n",
    "\n",
    "    Parameters:\n",
    "    ead_df (pd.DataFrame): DataFrame containing the 'ead' columns.\n",
    "    haz_trig_rp_lst (list): List of return periods corresponding to the 'ead' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Updated DataFrame with zero values replaced.\n",
    "    \"\"\"\n",
    "    # Extract the relevant columns and convert to numpy array for vectorized operations\n",
    "    values = ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].values\n",
    "\n",
    "    # Iterate over the columns, starting from the second column\n",
    "    for i in range(1, values.shape[1]):\n",
    "        # Replace zeros with the previous column's value\n",
    "        values[:, i] = np.where(values[:, i] == 0, values[:, i-1], values[:, i])\n",
    "\n",
    "    # Convert the numpy array back to a DataFrame and update the original DataFrame\n",
    "    ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]] = values\n",
    "\n",
    "    # Extract the relevant columns and convert to numpy array for vectorized operations\n",
    "    values = ead_df[['ead_{}_overlay'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0).values\n",
    "\n",
    "    # Iterate over the columns, starting from the second column\n",
    "    for i in range(1, values.shape[1]):\n",
    "        # Replace zeros with the previous column's value\n",
    "        values[:, i] = np.where(values[:, i] == 0, values[:, i-1], values[:, i])\n",
    "\n",
    "    # Convert the numpy array back to a DataFrame and update the original DataFrame\n",
    "    ead_df[['ead_{}_overlay'.format(rp_trig) for rp_trig in haz_trig_rp_lst]] = values\n",
    "\n",
    "    # Extract the relevant columns and convert to numpy array for vectorized operations\n",
    "    values = ead_df[['ead_{}_number_landslides'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0).values\n",
    "\n",
    "    # Iterate over the columns, starting from the second column\n",
    "    for i in range(1, values.shape[1]):\n",
    "        # Replace zeros with the previous column's value\n",
    "        values[:, i] = np.where(values[:, i] == 0, values[:, i-1], values[:, i])\n",
    "\n",
    "    # Convert the numpy array back to a DataFrame and update the original DataFrame\n",
    "    ead_df[['ead_{}_number_landslides'.format(rp_trig) for rp_trig in haz_trig_rp_lst]] = values \n",
    "    \n",
    "    return ead_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5118f-be07-4eee-ad09-0a1d72f28fa0",
   "metadata": {},
   "source": [
    "# Earthquake-triggered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6547c01e-841d-442a-aec6-21592168ba2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the total damage for landslide return period 2.5 given rainfall event of 475: 0.00\n",
      "This is the total damage for landslide return period 10.0 given rainfall event of 475: 403,832.69\n",
      "This is the total damage for landslide return period 20.0 given rainfall event of 475: 54,217,955.71\n",
      "This is the total damage for landslide return period 100.0 given rainfall event of 475: 520,322,413.04\n",
      "This is the total damage for landslide return period 200.0 given rainfall event of 475: 1,821,415,092.91\n",
      "This is the total damage for landslide return period 1000.0 given rainfall event of 475: 4,764,047,517.28\n",
      "Unique osm_id in original data: 175213\n",
      "Unique osm_id in pivoted data: 175213\n",
      "Missing osm_id values: set()\n",
      "This is the EAD given earthquake event of 475: 36,706,243.01489286\n",
      "This is the national EAD for earthquake-triggered landslides: 18391759.654317692\n",
      "This is the max EAD for earthquake-triggered landslides for a road segment: 292206.6695288195\n"
     ]
    }
   ],
   "source": [
    "# read parquets per return period\n",
    "haz_trig_rp_lst = [475]\n",
    "landslide_rp_lst = [2.5, 10.0, 20.0, 100.0, 200.0, 1000.0]\n",
    "road_types_lst = ['unclassified', 'primary', 'secondary', 'tertiary', 'residential', \n",
    "                                'trunk', 'trunk_link',  'motorway','motorway_link',  'primary_link','secondary_link', 'tertiary_link','road', 'track' ]\n",
    "#create df with all unique ID numbers, geometry and column ead\n",
    "ead_df = gpd.GeoDataFrame(columns=['osm_id', 'asset', 'geometry']+['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst] \n",
    "                          +['ead_{}_overlay'.format(rp_trig) for rp_trig in haz_trig_rp_lst] +['ead_{}_number_landslides'.format(rp_trig) for rp_trig in haz_trig_rp_lst], geometry='geometry')\n",
    "\n",
    "for rp_trig in haz_trig_rp_lst:\n",
    "    damage_data_path_list = eq_damage_data_path.iterdir()\n",
    "    rp_trig_path_list = [path for path in damage_data_path_list if '_trig{}'.format(rp_trig) in str(path)]\n",
    "\n",
    "    damages_dict = {key: pd.DataFrame() for key in landslide_rp_lst}\n",
    "    for data_path in rp_trig_path_list:\n",
    "        df = gpd.read_parquet(data_path)\n",
    "        damages_dict[df['return_period_landslide'].unique()[0]] = pd.concat([damages_dict[df['return_period_landslide'].unique()[0]], df], ignore_index=True)  #create dictionary with the return period \n",
    "\n",
    "    #modify dictionaries \n",
    "    non_empty_rps = [key for key, df in damages_dict.items() if not df.empty]\n",
    "    if non_empty_rps:\n",
    "        lowest_non_empty_rp = min(non_empty_rps)\n",
    "        damages_dict = {key: df for key, df in damages_dict.items() if key >= lowest_non_empty_rp} # Step 1: Remove all keys above this return period\n",
    "        highest_non_empty_rp = max(non_empty_rps)\n",
    "        damages_dict = {key: df for key, df in damages_dict.items() if key <= highest_non_empty_rp} # Step 2: Remove all keys below this return period\n",
    "        for rp in damages_dict.keys():\n",
    "            #print('This is the total damage for landslide return period {} given rainfall event of {}: {:,.2f}; exposed roads: {:.2f} km'.format(rp, rp_trig, damages_dict[rp]['Partial destruction (0.5)'].sum(), damages_dict[rp]['Overlay'].sum()/1000))\n",
    "            print('This is the total damage for landslide return period {} given rainfall event of {}: {:,.2f}'.format(rp, rp_trig, damages_dict[rp]['Partial destruction (0.5)'].sum()))   \n",
    "        \n",
    "        # Calculate EAD per OSM road segment for rainfall event\n",
    "        combined_df = pd.concat([damages_dict[rp] for rp in damages_dict.keys()]) #merge dataframes into one\n",
    "        combined_df['Partial destruction (0.5)'] = combined_df['Partial destruction (0.5)'].fillna(0)\n",
    "        temp_df = combined_df.drop_duplicates(subset=['osm_id']) # remove duplicates\n",
    "        ead_df = pd.merge(ead_df, temp_df[['osm_id', 'asset', 'geometry']], on=['osm_id', 'asset', 'geometry'], how='outer')\n",
    "        \n",
    "        pivoted_damages = combined_df.pivot_table(index='osm_id', columns='return_period_landslide', values='Partial destruction (0.5)', fill_value=0)\n",
    "        \n",
    "        print(\"Unique osm_id in original data:\", combined_df['osm_id'].nunique()) # Print unique osm_id from the original DataFrame\n",
    "        print(\"Unique osm_id in pivoted data:\", pivoted_damages.index.nunique()) # Print unique osm_id from the pivoted DataFrame\n",
    "        missing_ids = set(combined_df['osm_id']) - set(pivoted_damages.index) # Check if some osm_id values are missing from pivoted_damages\n",
    "        print(\"Missing osm_id values:\", missing_ids)\n",
    "        \n",
    "        ead_df['ead_{}'.format(rp_trig)] = ead_df.apply(lambda row: calculate_risk_vectorized(pivoted_damages.loc[row['osm_id']]) if row['osm_id'] in pivoted_damages.index else 0, axis=1)\n",
    "\n",
    "        #fill in overlay columns\n",
    "        overlay_dict = damages_dict[highest_non_empty_rp].set_index('osm_id')['Overlay'].to_dict()\n",
    "        ead_df['ead_{}_overlay'.format(rp_trig)] = ead_df['osm_id'].map(overlay_dict)\n",
    "\n",
    "        #fill in number of landslides columns\n",
    "        number_landslide_dict = damages_dict[highest_non_empty_rp].set_index('osm_id')['number of landslides'].to_dict()\n",
    "        ead_df['ead_{}_number_landslides'.format(rp_trig)] = ead_df['osm_id'].map(number_landslide_dict)\n",
    "\n",
    "ead_df = handle_zero_values(ead_df, haz_trig_rp_lst) # Handle 0 values for higher return periods with damages for the lower return periods\n",
    "\n",
    "# Calculate EAD for earthquake-triggered landslides\n",
    "ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]] = ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0)\n",
    "temp_df = (ead_df.filter(['osm_id']+['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst], axis=1)).set_index('osm_id') #create df with only ead columns\n",
    "ead_df['ead'] = ead_df.apply(lambda row: calculate_risk_vectorized(temp_df.loc[row['osm_id']]), axis=1)\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "for rp_trig in haz_trig_rp_lst:\n",
    "    print('This is the EAD given earthquake event of {}: {:,}'.format(rp_trig, ead_df['ead_{}'.format(rp_trig)].sum()))\n",
    "print('This is the national EAD for earthquake-triggered landslides: {}'.format(sum(ead_df['ead'])))\n",
    "print('This is the max EAD for earthquake-triggered landslides for a road segment: {}'.format(max(ead_df['ead'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cefb1cda-09fd-479d-9277-4b56e6690fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the road length exposed at national level: 19,067.70\n",
      "This is the EAD at national level: 18,391,759.65\n",
      "The expected annual damage, based on length of affected road segment: 964.55 dollar per km\n"
     ]
    }
   ],
   "source": [
    "# exposed roads\n",
    "print(\"This is the road length exposed at national level: {:,.2f}\".format(ead_df.ead_475_overlay.sum()/1000))\n",
    "print(\"This is the EAD at national level: {:,.2f}\".format(ead_df.ead.sum()))\n",
    "\n",
    "affected_road = ead_df.ead_475_overlay.sum()/1000\n",
    "damage = ead_df.ead.sum()\n",
    "print('The expected annual damage, based on length of affected road segment: {:,.2f} dollar per km'.format(damage/affected_road))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2760b0-e00c-423e-a5e0-a96ef5eac912",
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332b5d8-1e9b-4d2e-9cb4-e146e9e88e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnational_df = gpd.read_file(admin_path / 'gadm41_TJK.gpkg',layer=3)\n",
    "subnational_df = subnational_df.to_crs(3857)\n",
    "ead_df['GID_3'] = ead_df.apply(lambda road_segment: get_province(road_segment, subnational), axis=1)\n",
    "subnational_df = subnational_df.merge(ead_df[['GID_3','ead']].groupby('GID_3').sum(),left_on='GID_3',right_index=True)\n",
    "subnational_df[['NAME_2','ead']].groupby('NAME_2').sum().sort_values(by='ead',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab8f45-81d2-4736-9be3-c298231c0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnational_df['binned'] =  pd.cut(subnational_df.ead,[0,1e4,2.5e4,5e4,subnational_df.ead.max()],labels=['\\\\$1-$10,000','\\\\$10,000-$25,000','\\\\$25,000-$50,000','> $50,000'])\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "\n",
    "subnational_df.plot(column = 'binned',cmap='copper_r',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "subnational_df.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(figures_path /'landslide_eq_EAD_municipal.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417deae-7987-4469-a7e8-2f5e60ed0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnational_df.ead.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adddc08-633a-43fc-ae8f-944aabac08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_df['damage/km'] = ead_df.ead/(ead_df.ead_475_overlay/1000)\n",
    "ead_df['damage/km'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6fc1f4-5d46-4211-a0f8-1dc4fcbe6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD damages per km per road segment\n",
    "ead_df['damage/km_binned'] = pd.cut(ead_df['damage/km'],[0,2.5e2,5e2,1.5e3,ead_df['damage/km'].max()],labels=['\\\\$1-$250','\\\\$250-$500','\\\\$500-$1,500','> $1,500'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='damage/km_binned',cmap='copper_r',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(figures_path /'landslide_eq_EAD_km.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757c6c5-5dd8-49f4-b4ec-7d9f547d3573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29a3ab6-b815-4489-b15c-5f5d3cb66553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 1/1000 landslide events given a 475 year eq-RP: damages per OSM road segment\n",
    "damages_dict[1000]['binned'] = pd.cut(damages_dict[1000]['Partial destruction (0.5)'],[0,1e4,1e6,1e7,damages_dict[1000]['Partial destruction (0.5)'].max()],labels=['\\\\$1-$10,000','\\\\$10,000-$1,000,000','\\\\$1,000,000-$10,000,000','> $10,000,000'])\n",
    "damage_df = damages_dict[1000].to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "damage_df.plot(column = 'binned',cmap='Reds',legend=True,ax=ax)\n",
    "#damage_df.plot(column ='Partial destruction (0.5)',cmap='Reds',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f177bd7-8d8d-4328-9ef1-d51f025de439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 1/100 landslide events given a 475 year eq-RP: damages per OSM road segment\n",
    "damages_dict[100]['binned'] = pd.cut(damages_dict[100]['Partial destruction (0.5)'],[0,1e4,1e6,1e7,damages_dict[1000]['Partial destruction (0.5)'].max()],labels=['\\\\$1-$10,000','\\\\$10,000-$1,000,000','\\\\$1,000,000-$10,000,000','> $10,000,000'])\n",
    "damage_df = damages_dict[100].to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "damage_df.plot(column = 'binned',cmap='Reds',legend=True,ax=ax)\n",
    "#damage_df.plot(column ='Partial destruction (0.5)',cmap='Reds',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171f6cd-a462-4a26-9eca-f107189ade8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 1/20 landslide events given a 475 year eq-RP: damages per OSM road segment\n",
    "damages_dict[20]['binned'] = pd.cut(damages_dict[20]['Partial destruction (0.5)'],[0,1e4,1e6,1e7,damages_dict[1000]['Partial destruction (0.5)'].max()],labels=['\\\\$1-$10,000','\\\\$10,000-$1,000,000','\\\\$1,000,000-$10,000,000','> $10,000,000'])\n",
    "damage_df = damages_dict[20].to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "damage_df.plot(column = 'binned',cmap='Reds',legend=True,ax=ax)\n",
    "#damage_df.plot(column ='Partial destruction (0.5)',cmap='Reds',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abadbd67-ec40-4212-a9da-6bd93dc30e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD due to earthquake-triggered landslide events given a 475 year eq-RP: damages per OSM road segment\n",
    "ead_df['ead_475_binned'] = pd.cut(ead_df['ead_475'],[0,1e3,1e4,2.5e4,ead_df['ead_475'].max()],labels=['\\\\$1-$1,000','\\\\$1,000-$10,000','\\\\$10,000-$25,000','> $25,000'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='ead_475_binned',cmap='Reds',legend=True,ax=ax)\n",
    "#damage_df.plot(column ='Partial destruction (0.5)',cmap='Reds',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c74ff-aa32-4016-a37d-c1d830702aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD due to earthquake-triggered landslides: damages per OSM road segment\n",
    "ead_df['ead_binned'] = pd.cut(ead_df['ead'],[0,1e3,1e4,2.5e4,ead_df['ead'].max()],labels=['\\\\$1-$1,000','\\\\$1,000-$10,000','\\\\$10,000-$25,000','> $25,000'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='ead_binned',cmap='Reds',legend=True,ax=ax)\n",
    "#damage_df.plot(column ='Partial destruction (0.5)',cmap='Reds',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(figures_path /'landslide_eq_EAD.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6824d572-4fd1-4b4b-b78a-4cd7d1050264",
   "metadata": {},
   "source": [
    "# Rainfall-triggered "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a03b5-22e9-4119-b3a2-830596cbfff0",
   "metadata": {},
   "source": [
    "## Historical conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b0f017f-b92c-4f1f-8fe4-95869e32d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the total damage for landslide return period 20.0 given rainfall event of 5: 1,110,586.54\n",
      "This is the total damage for landslide return period 33.0 given rainfall event of 5: 10,735,423.25\n",
      "This is the total damage for landslide return period 50.0 given rainfall event of 5: 75,801,523.45\n",
      "This is the total damage for landslide return period 100.0 given rainfall event of 5: 418,841,420.82\n",
      "Unique osm_id in original data: 174224\n",
      "Unique osm_id in pivoted data: 174224\n",
      "Missing osm_id values: set()\n",
      "This is the total damage for landslide return period 10.0 given rainfall event of 25: 34,782,097.68\n",
      "This is the total damage for landslide return period 20.0 given rainfall event of 25: 194,891,991.45\n",
      "This is the total damage for landslide return period 33.0 given rainfall event of 25: 1,452,383,602.19\n",
      "This is the total damage for landslide return period 50.0 given rainfall event of 25: 7,526,826,624.95\n",
      "Unique osm_id in original data: 175213\n",
      "Unique osm_id in pivoted data: 175213\n",
      "Missing osm_id values: set()\n",
      "This is the total damage for landslide return period 7.0 given rainfall event of 200: 34,948,101.92\n",
      "This is the total damage for landslide return period 10.0 given rainfall event of 200: 198,582,908.15\n",
      "This is the total damage for landslide return period 20.0 given rainfall event of 200: 1,486,201,229.15\n",
      "This is the total damage for landslide return period 33.0 given rainfall event of 200: 8,054,911,740.96\n",
      "Unique osm_id in original data: 174935\n",
      "Unique osm_id in pivoted data: 174935\n",
      "Missing osm_id values: set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snn490\\AppData\\Local\\Temp\\ipykernel_6360\\2187923882.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  values = ead_df[['ead_{}_overlay'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0).values\n",
      "C:\\Users\\snn490\\AppData\\Local\\Temp\\ipykernel_6360\\2187923882.py:60: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  values = ead_df[['ead_{}_number_landslides'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0).values\n",
      "C:\\Users\\snn490\\AppData\\Local\\Temp\\ipykernel_6360\\4042794197.py:57: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]] = ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the EAD given rainfall event of 5: 7,751,663.496123953\n",
      "This is the EAD given rainfall event of 25: 234,410,034.19110712\n",
      "This is the EAD given rainfall event of 200: 400,158,077.3380545\n",
      "This is the EAD given rainfall event of 1000: 0\n",
      "This is the national EAD for rainfall-triggered landslides: 34578938.338525735\n",
      "This is the max EAD for rainfall-triggered landslides for a road segment: 275431.59939733293\n"
     ]
    }
   ],
   "source": [
    "#read parquets per return period\n",
    "haz_trig_rp_lst = [5, 25, 200, 1000]\n",
    "landslide_rp_lst = [5.0, 7.0, 10.0, 20.0, 33.0, 50.0, 100.0]\n",
    "road_types_lst = ['unclassified', 'primary', 'secondary', 'tertiary', 'residential', \n",
    "                                'trunk', 'trunk_link',  'motorway','motorway_link',  'primary_link','secondary_link', 'tertiary_link','road', 'track' ]\n",
    "\n",
    "#create df with all unique ID numbers, geometry and column ead\n",
    "ead_df = gpd.GeoDataFrame(columns=['osm_id', 'asset', 'geometry']+['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst] \n",
    "                          +['ead_{}_overlay'.format(rp_trig) for rp_trig in haz_trig_rp_lst] +['ead_{}_number_landslides'.format(rp_trig) for rp_trig in haz_trig_rp_lst], geometry='geometry')\n",
    "\n",
    "for rp_trig in haz_trig_rp_lst:\n",
    "    damage_data_path_list = his_rainfall_damage_data_path.iterdir()\n",
    "    rp_trig_path_list = [path for path in damage_data_path_list if '_trig{}'.format(rp_trig) in str(path)]\n",
    "\n",
    "    damages_dict = {key: pd.DataFrame() for key in landslide_rp_lst}\n",
    "    for data_path in rp_trig_path_list:\n",
    "        df = gpd.read_parquet(data_path)\n",
    "        damages_dict[df['return_period_landslide'].unique()[0]] = pd.concat([damages_dict[df['return_period_landslide'].unique()[0]], df], ignore_index=True)  #create dictionary with the return period \n",
    "\n",
    "    #modify dictionaries \n",
    "    non_empty_rps = [key for key, df in damages_dict.items() if not df.empty]\n",
    "    if non_empty_rps:\n",
    "        lowest_non_empty_rp = min(non_empty_rps)\n",
    "        damages_dict = {key: df for key, df in damages_dict.items() if key >= lowest_non_empty_rp} # Step 1: Remove all keys above this return period\n",
    "        highest_non_empty_rp = max(non_empty_rps)\n",
    "        damages_dict = {key: df for key, df in damages_dict.items() if key <= highest_non_empty_rp} # Step 2: Remove all keys below this return period\n",
    "        for rp in damages_dict.keys():\n",
    "            #print('This is the total damage for landslide return period {} given rainfall event of {}: {:,.2f}; exposed roads: {:.2f} km'.format(rp, rp_trig, damages_dict[rp]['Partial destruction (0.5)'].sum(), damages_dict[rp]['Overlay'].sum()/1000))\n",
    "            print('This is the total damage for landslide return period {} given rainfall event of {}: {:,.2f}'.format(rp, rp_trig, damages_dict[rp]['Partial destruction (0.5)'].sum()))   \n",
    "        \n",
    "        # Calculate EAD per OSM road segment for rainfall event\n",
    "        combined_df = pd.concat([damages_dict[rp] for rp in damages_dict.keys()]) #merge dataframes into one\n",
    "        combined_df['Partial destruction (0.5)'] = combined_df['Partial destruction (0.5)'].fillna(0)\n",
    "        temp_df = combined_df.drop_duplicates(subset=['osm_id']) # remove duplicates\n",
    "        ead_df = pd.merge(ead_df, temp_df[['osm_id', 'asset', 'geometry']], on=['osm_id', 'asset', 'geometry'], how='outer')\n",
    "        \n",
    "        pivoted_damages = combined_df.pivot_table(index='osm_id', columns='return_period_landslide', values='Partial destruction (0.5)', fill_value=0)\n",
    "        \n",
    "        print(\"Unique osm_id in original data:\", combined_df['osm_id'].nunique()) # Print unique osm_id from the original DataFrame\n",
    "        print(\"Unique osm_id in pivoted data:\", pivoted_damages.index.nunique()) # Print unique osm_id from the pivoted DataFrame\n",
    "        missing_ids = set(combined_df['osm_id']) - set(pivoted_damages.index) # Check if some osm_id values are missing from pivoted_damages\n",
    "        print(\"Missing osm_id values:\", missing_ids)\n",
    "        \n",
    "        ead_df['ead_{}'.format(rp_trig)] = ead_df.apply(lambda row: calculate_risk_vectorized(pivoted_damages.loc[row['osm_id']]) if row['osm_id'] in pivoted_damages.index else 0, axis=1)\n",
    "\n",
    "        #fill in overlay columns\n",
    "        overlay_dict = damages_dict[highest_non_empty_rp].set_index('osm_id')['Overlay'].to_dict()\n",
    "        ead_df['ead_{}_overlay'.format(rp_trig)] = ead_df['osm_id'].map(overlay_dict)\n",
    "\n",
    "        #fill in number of landslides columns\n",
    "        number_landslide_dict = damages_dict[highest_non_empty_rp].set_index('osm_id')['number of landslides'].to_dict()\n",
    "        ead_df['ead_{}_number_landslides'.format(rp_trig)] = ead_df['osm_id'].map(number_landslide_dict)\n",
    "\n",
    "ead_df = handle_zero_values(ead_df, haz_trig_rp_lst) # Handle 0 values for higher return periods with damages for the lower return periods\n",
    "\n",
    "# Calculate EAD for landslide-triggered landslides\n",
    "ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]] = ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0)\n",
    "temp_df = (ead_df.filter(['osm_id']+['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst], axis=1)).set_index('osm_id') #create df with only ead columns\n",
    "ead_df['ead'] = ead_df.apply(lambda row: calculate_risk_vectorized(temp_df.loc[row['osm_id']]), axis=1)\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "for rp_trig in haz_trig_rp_lst:\n",
    "    print('This is the EAD given rainfall event of {}: {:,}'.format(rp_trig, ead_df['ead_{}'.format(rp_trig)].sum()))\n",
    "print('This is the national EAD for rainfall-triggered landslides: {}'.format(sum(ead_df['ead'])))\n",
    "print('This is the max EAD for rainfall-triggered landslides for a road segment: {}'.format(max(ead_df['ead'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b963d24-8eb2-40aa-a65d-22a1a03c5c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the road length exposed at national level: 33,011.83\n",
      "This is the EAD at national level: 34,578,938.34\n",
      "The expected annual damage, based on length of affected road segment: 1,047.47 dollar per km\n"
     ]
    }
   ],
   "source": [
    "# exposed roads\n",
    "print(\"This is the road length exposed at national level: {:,.2f}\".format(ead_df.ead_1000_overlay.sum()/1000))\n",
    "print(\"This is the EAD at national level: {:,.2f}\".format(ead_df.ead.sum()))\n",
    "\n",
    "affected_road = ead_df.ead_1000_overlay.sum()/1000\n",
    "damage = ead_df.ead.sum()\n",
    "print('The expected annual damage, based on length of affected road segment: {:,.2f} dollar per km'.format(damage/affected_road))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770c87c-4572-4974-a874-718d8f24f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnational_df = gpd.read_file(admin_path / 'gadm41_TJK.gpkg',layer=3)\n",
    "subnational_df = subnational_df.to_crs(3857)\n",
    "ead_df['GID_3'] = ead_df.apply(lambda road_segment: get_province(road_segment, subnational), axis=1)\n",
    "subnational_df = subnational_df.merge(ead_df[['GID_3','ead']].groupby('GID_3').sum(),left_on='GID_3',right_index=True)\n",
    "subnational_df[['NAME_2','ead']].groupby('NAME_2').sum().sort_values(by='ead',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f092ac-2426-4855-ac44-eda206b6fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnational_df['binned'] =  pd.cut(subnational_df.ead,[0,1e4,5e4,1.5e5,2.5e5,subnational_df.ead.max()],labels=['\\\\$1-$10,000','\\\\$10,000-$50,000','\\\\$50,000-$150,000',\n",
    "                                                                                                       '\\\\$150,000-$250,000','> $250,000'])\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "\n",
    "subnational_df.plot(column = 'binned',cmap='copper_r',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "subnational_df.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(figures_path /'landslide_rf_historical_EAD_municipal.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b1e96-805d-4bcc-a8a0-d280b1d65bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnational_df.ead.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6dfefd-d530-400d-b467-dca28911566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_df['damage/km'] = ead_df.ead/(ead_df.ead_1000_overlay/1000)\n",
    "ead_df['damage/km'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a217a-385b-4ca3-9abf-a9ff2052f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD damages per km per road segment\n",
    "ead_df['damage/km_binned'] = pd.cut(ead_df['damage/km'],[0,1e3,2.5e3,5.5e3,ead_df['damage/km'].max()],labels=['\\\\$1-$1,000','\\\\$1,000-$2,500','\\\\$2,500-$5,500','> $5,500'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='damage/km_binned',cmap='copper_r',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(figures_path /'landslide_rf_historical_EAD_km.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21be0ef-1d3c-445d-9bf0-0d82aa4d2129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a053a-863c-47a4-b3c3-85ed14620900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD due to rainfall-triggered landslide events due to 1000 year RP rainfall: damages per OSM road segment\n",
    "ead_df['ead_1000_binned'] = pd.cut(ead_df['ead_1000'],[0,1e3,1e4,2.5e4,ead_df['ead_1000'].max()],labels=['\\\\$1-$1,000','\\\\$1,000-$10,000','\\\\$10,000-$25,000','> $25,000'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='ead_1000_binned',cmap='Reds',legend=True,ax=ax)\n",
    "#damage_df.plot(column ='Partial destruction (0.5)',cmap='Reds',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2fba5-f07d-4c20-929e-4f3f305de7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD due to rainfall-triggered landslide events due to 25 year RP rainfall: damages per OSM road segment\n",
    "ead_df['ead_25_binned'] = pd.cut(ead_df['ead_25'],[0,1e3,1e4,2.5e4,ead_df['ead_1000'].max()],labels=['\\\\$1-$1,000','\\\\$1,000-$10,000','\\\\$10,000-$25,000','> $25,000'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='ead_25_binned',cmap='Reds',legend=True,ax=ax)\n",
    "#damage_df.plot(column ='Partial destruction (0.5)',cmap='Reds',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ae14ee-695b-4e5f-8c2c-5f8cd0e7c2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD due to rainfall-triggered landslides: damages per OSM road segment\n",
    "ead_df['ead_binned'] = pd.cut(ead_df['ead'],[0,1e3,1e4,2.5e4,ead_df['ead'].max()],labels=['\\\\$1-$1,000','\\\\$1,000-$10,000','\\\\$10,000-$25,000','> $25,000'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='ead_binned',cmap='Reds',legend=True,ax=ax)\n",
    "#damage_df.plot(column ='Partial destruction (0.5)',cmap='Reds',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(figures_path /'landslide_rf_historical_EAD.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325d1ee-1904-4cbb-96bb-ad8e7ab3d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_df.ead_binned.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4840ccd-ac2c-4105-be7f-d658975db674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project road of interest\n",
    "dangara_gulliston_ids = dangara_gulliston_ids = ['629623298', '588578885', '667337582', '32623282', '32623136']\n",
    "project_df = ead_df[ead_df['osm_id'].isin(dangara_gulliston_ids)]\n",
    "\n",
    "project_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9c06d-c978-4b1b-be0a-4f8afea8cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shapely.length(project_df['geometry'])/1000) # length of road segments in km\n",
    "print(sum(shapely.length(project_df['geometry'])/1000)) # total length of road segments in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae32c36-8b48-4703-937a-f4ab5b5e8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "damage = sum(project_df['ead'])\n",
    "affected_road = sum(project_df['ead_1000_overlay'])/1000\n",
    "number_of_landslides = sum(project_df['ead_1000_number_landslides'])\n",
    "road_segments_length = 22.976544 + 20.829034 + 10.498568\n",
    "\n",
    "print('The expected annual damage for Dangara-Gulliston road project, based on total length of project road: {:.2f} dollar per km'.format(damage/67.34681578690605))\n",
    "print('The expected annual damage for Dangara-Gulliston road project, based on length of affected OSM road segment: {:.2f} dollar per km'.format(damage/road_segments_length)) \n",
    "print('The expected annual damage for Dangara-Gulliston road project, based on length of affected road segment: {:.2f} dollar per km'.format(damage/affected_road)) \n",
    "print('The expected annual damage for Dangara-Gulliston road project per landslide event: {:.2f} dollar'.format(damage/number_of_landslides)) #shouldn't we divide by the average landslides per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93352b27-1117-4fb9-9f52-85f4110a02eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(project_df['ead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e9d85-18f1-473b-917a-ed8054475607",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(project_df['ead_1000_overlay'])/1000 #affected road segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb16024-fe69-4516-a29d-30176d182b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd78b9a5-5591-485a-a68a-e69151690381",
   "metadata": {},
   "source": [
    "## Future conditions SSP126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5899215f-6763-40ef-8694-3037888ed89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the total damage for landslide return period 20.0 given rainfall event of 5: 1,110,586.54\n",
      "This is the total damage for landslide return period 33.0 given rainfall event of 5: 10,875,160.28\n",
      "This is the total damage for landslide return period 50.0 given rainfall event of 5: 77,387,451.18\n",
      "This is the total damage for landslide return period 100.0 given rainfall event of 5: 439,990,837.57\n",
      "Unique osm_id in original data: 174224\n",
      "Unique osm_id in pivoted data: 174224\n",
      "Missing osm_id values: set()\n",
      "This is the total damage for landslide return period 10.0 given rainfall event of 25: 34,782,097.68\n",
      "This is the total damage for landslide return period 20.0 given rainfall event of 25: 195,470,870.27\n",
      "This is the total damage for landslide return period 33.0 given rainfall event of 25: 1,476,786,401.08\n",
      "This is the total damage for landslide return period 50.0 given rainfall event of 25: 7,844,206,436.04\n",
      "Unique osm_id in original data: 175213\n",
      "Unique osm_id in pivoted data: 175213\n",
      "Missing osm_id values: set()\n",
      "This is the total damage for landslide return period 7.0 given rainfall event of 200: 34,948,101.92\n",
      "This is the total damage for landslide return period 10.0 given rainfall event of 200: 199,199,260.56\n",
      "This is the total damage for landslide return period 20.0 given rainfall event of 200: 1,512,035,576.73\n",
      "This is the total damage for landslide return period 33.0 given rainfall event of 200: 8,427,816,273.27\n",
      "Unique osm_id in original data: 174935\n",
      "Unique osm_id in pivoted data: 174935\n",
      "Missing osm_id values: set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snn490\\AppData\\Local\\Temp\\ipykernel_6360\\2187923882.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  values = ead_df[['ead_{}_overlay'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0).values\n",
      "C:\\Users\\snn490\\AppData\\Local\\Temp\\ipykernel_6360\\2187923882.py:60: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  values = ead_df[['ead_{}_number_landslides'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0).values\n",
      "C:\\Users\\snn490\\AppData\\Local\\Temp\\ipykernel_6360\\386716094.py:57: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]] = ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the EAD given rainfall event of 5: 8,087,100.369983716\n",
      "This is the EAD given rainfall event of 25: 242,778,832.3195557\n",
      "This is the EAD given rainfall event of 200: 416,059,663.5123421\n",
      "This is the EAD given rainfall event of 1000: 0\n",
      "This is the national EAD for rainfall-triggered landslides: 35873937.578193165\n",
      "This is the max EAD for rainfall-triggered landslides for a road segment: 275431.59939733293\n"
     ]
    }
   ],
   "source": [
    "#read parquets per return period\n",
    "haz_trig_rp_lst = [5, 25, 200, 1000]\n",
    "landslide_rp_lst = [5.0, 7.0, 10.0, 20.0, 33.0, 50.0, 100.0]\n",
    "road_types_lst = ['unclassified', 'primary', 'secondary', 'tertiary', 'residential', \n",
    "                                'trunk', 'trunk_link',  'motorway','motorway_link',  'primary_link','secondary_link', 'tertiary_link','road', 'track' ]\n",
    "\n",
    "#create df with all unique ID numbers, geometry and column ead\n",
    "ead_df = gpd.GeoDataFrame(columns=['osm_id', 'asset', 'geometry']+['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst] \n",
    "                          +['ead_{}_overlay'.format(rp_trig) for rp_trig in haz_trig_rp_lst] +['ead_{}_number_landslides'.format(rp_trig) for rp_trig in haz_trig_rp_lst], geometry='geometry')\n",
    "\n",
    "for rp_trig in haz_trig_rp_lst:\n",
    "    damage_data_path_list = fut126_rainfall_damage_data_path.iterdir()\n",
    "    rp_trig_path_list = [path for path in damage_data_path_list if '_trig{}'.format(rp_trig) in str(path)]\n",
    "\n",
    "    damages_dict = {key: pd.DataFrame() for key in landslide_rp_lst}\n",
    "    for data_path in rp_trig_path_list:\n",
    "        df = gpd.read_parquet(data_path)\n",
    "        damages_dict[df['return_period_landslide'].unique()[0]] = pd.concat([damages_dict[df['return_period_landslide'].unique()[0]], df], ignore_index=True)  #create dictionary with the return period \n",
    "\n",
    "    #modify dictionaries \n",
    "    non_empty_rps = [key for key, df in damages_dict.items() if not df.empty]\n",
    "    if non_empty_rps:\n",
    "        lowest_non_empty_rp = min(non_empty_rps)\n",
    "        damages_dict = {key: df for key, df in damages_dict.items() if key >= lowest_non_empty_rp} # Step 1: Remove all keys above this return period\n",
    "        highest_non_empty_rp = max(non_empty_rps)\n",
    "        damages_dict = {key: df for key, df in damages_dict.items() if key <= highest_non_empty_rp} # Step 2: Remove all keys below this return period\n",
    "        for rp in damages_dict.keys():\n",
    "            #print('This is the total damage for landslide return period {} given rainfall event of {}: {:,.2f}; exposed roads: {:.2f} km'.format(rp, rp_trig, damages_dict[rp]['Partial destruction (0.5)'].sum(), damages_dict[rp]['Overlay'].sum()/1000))\n",
    "            print('This is the total damage for landslide return period {} given rainfall event of {}: {:,.2f}'.format(rp, rp_trig, damages_dict[rp]['Partial destruction (0.5)'].sum()))   \n",
    "        \n",
    "        # Calculate EAD per OSM road segment for rainfall event\n",
    "        combined_df = pd.concat([damages_dict[rp] for rp in damages_dict.keys()]) #merge dataframes into one\n",
    "        combined_df['Partial destruction (0.5)'] = combined_df['Partial destruction (0.5)'].fillna(0)\n",
    "        temp_df = combined_df.drop_duplicates(subset=['osm_id']) # remove duplicates\n",
    "        ead_df = pd.merge(ead_df, temp_df[['osm_id', 'asset', 'geometry']], on=['osm_id', 'asset', 'geometry'], how='outer')\n",
    "        \n",
    "        pivoted_damages = combined_df.pivot_table(index='osm_id', columns='return_period_landslide', values='Partial destruction (0.5)', fill_value=0)\n",
    "        \n",
    "        print(\"Unique osm_id in original data:\", combined_df['osm_id'].nunique()) # Print unique osm_id from the original DataFrame\n",
    "        print(\"Unique osm_id in pivoted data:\", pivoted_damages.index.nunique()) # Print unique osm_id from the pivoted DataFrame\n",
    "        missing_ids = set(combined_df['osm_id']) - set(pivoted_damages.index) # Check if some osm_id values are missing from pivoted_damages\n",
    "        print(\"Missing osm_id values:\", missing_ids)\n",
    "        \n",
    "        ead_df['ead_{}'.format(rp_trig)] = ead_df.apply(lambda row: calculate_risk_vectorized(pivoted_damages.loc[row['osm_id']]) if row['osm_id'] in pivoted_damages.index else 0, axis=1)\n",
    "\n",
    "        #fill in overlay columns\n",
    "        overlay_dict = damages_dict[highest_non_empty_rp].set_index('osm_id')['Overlay'].to_dict()\n",
    "        ead_df['ead_{}_overlay'.format(rp_trig)] = ead_df['osm_id'].map(overlay_dict)\n",
    "\n",
    "        #fill in number of landslides columns\n",
    "        number_landslide_dict = damages_dict[highest_non_empty_rp].set_index('osm_id')['number of landslides'].to_dict()\n",
    "        ead_df['ead_{}_number_landslides'.format(rp_trig)] = ead_df['osm_id'].map(number_landslide_dict)\n",
    "\n",
    "ead_df = handle_zero_values(ead_df, haz_trig_rp_lst) # Handle 0 values for higher return periods with damages for the lower return periods\n",
    "\n",
    "# Calculate EAD for earthquake-triggered landslides\n",
    "ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]] = ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0)\n",
    "temp_df = (ead_df.filter(['osm_id']+['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst], axis=1)).set_index('osm_id')\n",
    "ead_df['ead'] = ead_df.apply(lambda row: calculate_risk_vectorized(temp_df.loc[row['osm_id']]), axis=1)\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "for rp_trig in haz_trig_rp_lst:\n",
    "    print('This is the EAD given rainfall event of {}: {:,}'.format(rp_trig, ead_df['ead_{}'.format(rp_trig)].sum()))\n",
    "print('This is the national EAD for rainfall-triggered landslides: {}'.format(sum(ead_df['ead'])))\n",
    "print('This is the max EAD for rainfall-triggered landslides for a road segment: {}'.format(max(ead_df['ead'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c682d3e-657e-47c8-ba72-d0a4be9024f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the road length exposed at national level: 34,746.06\n",
      "This is the EAD at national level: 35,873,937.58\n",
      "The expected annual damage, based on length of affected road segment: 1,032.46 dollar per km\n"
     ]
    }
   ],
   "source": [
    "# exposed roads\n",
    "print(\"This is the road length exposed at national level: {:,.2f}\".format(ead_df.ead_1000_overlay.sum()/1000))\n",
    "print(\"This is the EAD at national level: {:,.2f}\".format(ead_df.ead.sum()))\n",
    "\n",
    "affected_road = ead_df.ead_1000_overlay.sum()/1000\n",
    "damage = ead_df.ead.sum()\n",
    "print('The expected annual damage, based on length of affected road segment: {:,.2f} dollar per km'.format(damage/affected_road))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b848d62-b6f9-4254-817c-fa7eb90045f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318639b-5bcb-4895-8272-c902e732fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnational_df = gpd.read_file(admin_path / 'gadm41_TJK.gpkg',layer=3)\n",
    "subnational_df = subnational_df.to_crs(3857)\n",
    "ead_df['GID_3'] = ead_df.apply(lambda road_segment: get_province(road_segment, subnational), axis=1)\n",
    "subnational_df = subnational_df.merge(ead_df[['GID_3','ead']].groupby('GID_3').sum(),left_on='GID_3',right_index=True)\n",
    "subnational_df[['NAME_2','ead']].groupby('NAME_2').sum().sort_values(by='ead',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9ace06-768e-4ff8-a98e-0f615c6f5e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnational_df['binned'] =  pd.cut(subnational_df.ead,[0,1e4,5e4,1.5e5,3e5,subnational_df.ead.max()],labels=['\\\\$1-$10,000','\\\\$10,000-$50,000','\\\\$50,000-$150,000',\n",
    "                                                                                                       '\\\\$150,000-$300,000','> $300,000'])\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "\n",
    "subnational_df.plot(column = 'binned',cmap='copper_r',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "subnational_df.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(figures_path /'landslide_rf_SSP126_EAD_municipal.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa52165-74e9-481f-9cfa-7220016e63c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnational_df.ead.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f36c0-94ec-4ed2-9ef4-cf034bca5df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_df['damage/km'] = ead_df.ead/(ead_df.ead_1000_overlay/1000)\n",
    "ead_df['damage/km'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4628a8bf-6307-4ee8-90c9-f4b3ddf84598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD damages per km per road segment\n",
    "ead_df['damage/km_binned'] = pd.cut(ead_df['damage/km'],[0,1e3,3e3,7e3,ead_df['damage/km'].max()],labels=['\\\\$1-$1,000','\\\\$1,000-$3,000','\\\\$3,000-$7,000','> $7,000'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='damage/km_binned',cmap='copper_r',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(figures_path /'landslide_rf_SSP126_EAD_km.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f2405e-e169-4fb3-ba2d-fab577d290c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6318ea8c-28ec-4145-8c42-f74bb491dfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b76a3-e540-4931-bdde-6c9158143407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f36274-e0e7-4ace-a6b1-250f9f1a23bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da8b96d-1453-4a68-acf7-18e83d85c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD due to rainfall-triggered landslides: damages per OSM road segment\n",
    "ead_df['ead_binned'] = pd.cut(ead_df['ead'],[0,1e3,1e4,2.5e4,ead_df['ead'].max()],labels=['\\\\$1-$1,000','\\\\$1,000-$10,000','\\\\$10,000-$25,000','> $25,000'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='ead_binned',cmap='Reds',legend=True,ax=ax)\n",
    "#damage_df.plot(column ='Partial destruction (0.5)',cmap='Reds',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(figures_path /'landslide_rf_ssp126_EAD.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dca9542-9cda-4a14-9b61-809674a0a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_df.ead.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684d957-2b67-48b4-9578-ad268ceb6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_df.ead_binned.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3aca1-aadc-4b65-8516-5a6cbf2f1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project road of interest\n",
    "dangara_gulliston_ids = dangara_gulliston_ids = ['629623298', '588578885', '667337582', '32623282', '32623136']\n",
    "project_df = ead_df[ead_df['osm_id'].isin(dangara_gulliston_ids)]\n",
    "\n",
    "project_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb713cbf-01eb-4f3a-aee4-20a9a50c0aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shapely.length(project_df['geometry'])/1000) # length of road segments in km\n",
    "print(sum(shapely.length(project_df['geometry'])/1000)) # total length of road segments in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084347a0-fc3d-4d2a-a746-b6b7749e4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "damage = sum(project_df['ead'])\n",
    "affected_road = sum(project_df['ead_1000_overlay'])/1000\n",
    "number_of_landslides = sum(project_df['ead_1000_number_landslides'])\n",
    "road_segments_length = 22.976544 + 20.829034 + 10.498568\n",
    "\n",
    "print('The expected annual damage for Dangara-Gulliston road project, based on total length of project road: {:.2f} dollar per km'.format(damage/67.34681578690605))\n",
    "print('The expected annual damage for Dangara-Gulliston road project, based on length of affected OSM road segment: {:.2f} dollar per km'.format(damage/road_segments_length)) \n",
    "print('The expected annual damage for Dangara-Gulliston road project, based on length of affected road segment: {:.2f} dollar per km'.format(damage/affected_road)) \n",
    "print('The expected annual damage for Dangara-Gulliston road project per landslide event: {:.2f} dollar'.format(damage/number_of_landslides)) #shouldn't we divide by the average landslides per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f247f-71fb-462e-9d80-07ed1570051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(project_df['ead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192e92f2-63cf-488b-adaa-c2a86fd76a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(project_df['ead_1000_overlay'])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c5860-17c4-48a7-b663-d1a05cce5023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c30ecc1-2d19-4b90-9cb3-17691e827b0e",
   "metadata": {},
   "source": [
    "## Future conditions SSP585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b510fea8-6367-4a13-ab38-4bbf167be0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the total damage for landslide return period 20.0 given rainfall event of 5: 1,110,586.54\n",
      "This is the total damage for landslide return period 33.0 given rainfall event of 5: 10,875,160.28\n",
      "This is the total damage for landslide return period 50.0 given rainfall event of 5: 77,387,451.18\n",
      "This is the total damage for landslide return period 100.0 given rainfall event of 5: 439,990,837.57\n",
      "Unique osm_id in original data: 174224\n",
      "Unique osm_id in pivoted data: 174224\n",
      "Missing osm_id values: set()\n",
      "This is the total damage for landslide return period 10.0 given rainfall event of 25: 55,679,639.80\n",
      "This is the total damage for landslide return period 20.0 given rainfall event of 25: 272,716,100.19\n",
      "This is the total damage for landslide return period 33.0 given rainfall event of 25: 1,691,724,216.00\n",
      "This is the total damage for landslide return period 50.0 given rainfall event of 25: 8,057,225,362.03\n",
      "Unique osm_id in original data: 175213\n",
      "Unique osm_id in pivoted data: 175213\n",
      "Missing osm_id values: set()\n",
      "This is the total damage for landslide return period 7.0 given rainfall event of 200: 55,845,644.04\n",
      "This is the total damage for landslide return period 10.0 given rainfall event of 200: 276,444,490.48\n",
      "This is the total damage for landslide return period 20.0 given rainfall event of 200: 1,727,148,591.00\n",
      "This is the total damage for landslide return period 33.0 given rainfall event of 200: 8,667,080,773.33\n",
      "Unique osm_id in original data: 174935\n",
      "Unique osm_id in pivoted data: 174935\n",
      "Missing osm_id values: set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snn490\\AppData\\Local\\Temp\\ipykernel_6360\\2187923882.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  values = ead_df[['ead_{}_overlay'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0).values\n",
      "C:\\Users\\snn490\\AppData\\Local\\Temp\\ipykernel_6360\\2187923882.py:60: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  values = ead_df[['ead_{}_number_landslides'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0).values\n",
      "C:\\Users\\snn490\\AppData\\Local\\Temp\\ipykernel_6360\\517468123.py:56: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]] = ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the EAD given rainfall event of 5: 8,087,100.369983716\n",
      "This is the EAD given rainfall event of 25: 263,978,859.99890238\n",
      "This is the EAD given rainfall event of 200: 446,153,137.93574005\n",
      "This is the EAD given rainfall event of 1000: 0\n",
      "This is the national EAD for rainfall-triggered landslides: 38542809.76389298\n",
      "This is the max EAD for rainfall-triggered landslides for a road segment: 696089.7445629857\n"
     ]
    }
   ],
   "source": [
    "#read parquets per return period\n",
    "haz_trig_rp_lst = [5, 25, 200, 1000]\n",
    "landslide_rp_lst = [5.0, 7.0, 10.0, 20.0, 33.0, 50.0, 100.0]\n",
    "road_types_lst = ['primary']\n",
    "\n",
    "#create df with all unique ID numbers, geometry and column ead\n",
    "ead_df = gpd.GeoDataFrame(columns=['osm_id', 'asset', 'geometry']+['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst] \n",
    "                          +['ead_{}_overlay'.format(rp_trig) for rp_trig in haz_trig_rp_lst] +['ead_{}_number_landslides'.format(rp_trig) for rp_trig in haz_trig_rp_lst], geometry='geometry')\n",
    "\n",
    "for rp_trig in haz_trig_rp_lst:\n",
    "    damage_data_path_list = fut585_rainfall_damage_data_path.iterdir()\n",
    "    rp_trig_path_list = [path for path in damage_data_path_list if '_trig{}'.format(rp_trig) in str(path)]\n",
    "\n",
    "    damages_dict = {key: pd.DataFrame() for key in landslide_rp_lst}\n",
    "    for data_path in rp_trig_path_list:\n",
    "        df = gpd.read_parquet(data_path)\n",
    "        damages_dict[df['return_period_landslide'].unique()[0]] = pd.concat([damages_dict[df['return_period_landslide'].unique()[0]], df], ignore_index=True)  #create dictionary with the return period \n",
    "\n",
    "    #modify dictionaries \n",
    "    non_empty_rps = [key for key, df in damages_dict.items() if not df.empty]\n",
    "    if non_empty_rps:\n",
    "        lowest_non_empty_rp = min(non_empty_rps)\n",
    "        damages_dict = {key: df for key, df in damages_dict.items() if key >= lowest_non_empty_rp} # Step 1: Remove all keys above this return period\n",
    "        highest_non_empty_rp = max(non_empty_rps)\n",
    "        damages_dict = {key: df for key, df in damages_dict.items() if key <= highest_non_empty_rp} # Step 2: Remove all keys below this return period\n",
    "        for rp in damages_dict.keys():\n",
    "            #print('This is the total damage for landslide return period {} given rainfall event of {}: {:,.2f}; exposed roads: {:.2f} km'.format(rp, rp_trig, damages_dict[rp]['Partial destruction (0.5)'].sum(), damages_dict[rp]['Overlay'].sum()/1000))\n",
    "            print('This is the total damage for landslide return period {} given rainfall event of {}: {:,.2f}'.format(rp, rp_trig, damages_dict[rp]['Partial destruction (0.5)'].sum()))   \n",
    "        \n",
    "        # Calculate EAD per OSM road segment for rainfall event\n",
    "        combined_df = pd.concat([damages_dict[rp] for rp in damages_dict.keys()]) #merge dataframes into one\n",
    "        combined_df['Partial destruction (0.5)'] = combined_df['Partial destruction (0.5)'].fillna(0)\n",
    "        temp_df = combined_df.drop_duplicates(subset=['osm_id']) # remove duplicates\n",
    "        ead_df = pd.merge(ead_df, temp_df[['osm_id', 'asset', 'geometry']], on=['osm_id', 'asset', 'geometry'], how='outer')\n",
    "        \n",
    "        pivoted_damages = combined_df.pivot_table(index='osm_id', columns='return_period_landslide', values='Partial destruction (0.5)', fill_value=0)\n",
    "        \n",
    "        print(\"Unique osm_id in original data:\", combined_df['osm_id'].nunique()) # Print unique osm_id from the original DataFrame\n",
    "        print(\"Unique osm_id in pivoted data:\", pivoted_damages.index.nunique()) # Print unique osm_id from the pivoted DataFrame\n",
    "        missing_ids = set(combined_df['osm_id']) - set(pivoted_damages.index) # Check if some osm_id values are missing from pivoted_damages\n",
    "        print(\"Missing osm_id values:\", missing_ids)\n",
    "        \n",
    "        ead_df['ead_{}'.format(rp_trig)] = ead_df.apply(lambda row: calculate_risk_vectorized(pivoted_damages.loc[row['osm_id']]) if row['osm_id'] in pivoted_damages.index else 0, axis=1)\n",
    "\n",
    "        #fill in overlay columns\n",
    "        overlay_dict = damages_dict[highest_non_empty_rp].set_index('osm_id')['Overlay'].to_dict()\n",
    "        ead_df['ead_{}_overlay'.format(rp_trig)] = ead_df['osm_id'].map(overlay_dict)\n",
    "\n",
    "        #fill in number of landslides columns\n",
    "        number_landslide_dict = damages_dict[highest_non_empty_rp].set_index('osm_id')['number of landslides'].to_dict()\n",
    "        ead_df['ead_{}_number_landslides'.format(rp_trig)] = ead_df['osm_id'].map(number_landslide_dict)\n",
    "\n",
    "ead_df = handle_zero_values(ead_df, haz_trig_rp_lst) # Handle 0 values for higher return periods with damages for the lower return periods\n",
    "\n",
    "# Calculate EAD for earthquake-triggered landslides\n",
    "ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]] = ead_df[['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst]].fillna(0)\n",
    "temp_df = (ead_df.filter(['osm_id']+['ead_{}'.format(rp_trig) for rp_trig in haz_trig_rp_lst], axis=1)).set_index('osm_id')\n",
    "ead_df['ead'] = ead_df.apply(lambda row: calculate_risk_vectorized(temp_df.loc[row['osm_id']]), axis=1)\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "for rp_trig in haz_trig_rp_lst:\n",
    "    print('This is the EAD given rainfall event of {}: {:,}'.format(rp_trig, ead_df['ead_{}'.format(rp_trig)].sum()))\n",
    "print('This is the national EAD for rainfall-triggered landslides: {}'.format(sum(ead_df['ead'])))\n",
    "print('This is the max EAD for rainfall-triggered landslides for a road segment: {}'.format(max(ead_df['ead'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6857509a-1e4c-4a1e-bcbc-5b07e30f685c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the road length exposed at national level: 35,801.47\n",
      "This is the EAD at national level: 38,542,809.76\n",
      "The expected annual damage based on length of affected road segment: 1,076.57 dollar per km\n"
     ]
    }
   ],
   "source": [
    "# exposed roads\n",
    "print(\"This is the road length exposed at national level: {:,.2f}\".format(ead_df.ead_1000_overlay.sum()/1000))\n",
    "print(\"This is the EAD at national level: {:,.2f}\".format(ead_df.ead.sum()))\n",
    "\n",
    "affected_road = ead_df.ead_1000_overlay.sum()/1000\n",
    "damage = ead_df.ead.sum()\n",
    "print('The expected annual damage based on length of affected road segment: {:,.2f} dollar per km'.format(damage/affected_road))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7378cd7a-d391-4092-9568-7956baa332e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988782a-cd29-4dca-898c-6c720b6d2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnational_df = gpd.read_file(admin_path / 'gadm41_TJK.gpkg',layer=3)\n",
    "subnational_df = subnational_df.to_crs(3857)\n",
    "ead_df['GID_3'] = ead_df.apply(lambda road_segment: get_province(road_segment, subnational), axis=1)\n",
    "subnational_df = subnational_df.merge(ead_df[['GID_3','ead']].groupby('GID_3').sum(),left_on='GID_3',right_index=True)\n",
    "subnational_df[['NAME_2','ead']].groupby('NAME_2').sum().sort_values(by='ead',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b9662-a6da-45f8-aa1c-2a0f50455bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnational_df['binned'] =  pd.cut(subnational_df.ead,[0,1e4,5e4,1.5e5,3e5,subnational_df.ead.max()],labels=['\\\\$1-$10,000','\\\\$10,000-$50,000','\\\\$50,000-$150,000',\n",
    "                                                                                                       '\\\\$150,000-$300,000','> $300,000'])\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "\n",
    "subnational_df.plot(column = 'binned',cmap='copper_r',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "subnational_df.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(figures_path /'landslide_rf_SSP585_EAD_municipal.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d483b169-39cb-402b-85b3-16e57e46af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnational_df.ead.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef59f9a-2996-47b9-9c25-004d22833a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ead_df['damage/km'] = ead_df.ead/(ead_df.ead_1000_overlay/1000)\n",
    "ead_df['damage/km'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2ed8b-d6ca-4cb1-af9b-e08aa2cfb561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD damages per km per road segment\n",
    "ead_df['damage/km_binned'] = pd.cut(ead_df['damage/km'],[0,1e3,3e3,7e3,ead_df['damage/km'].max()],labels=['\\\\$1-$1,000','\\\\$1,000-$3,000','\\\\$3,000-$7,000','> $7,000'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='damage/km_binned',cmap='copper_r',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(figures_path /'landslide_rf_SSP585_EAD_km.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe3501-7e2e-4db5-9276-b10b26b1cd65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c44b6-f85a-4b0d-b337-b1a464d65024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD due to rainfall-triggered landslide events due to 1000 year RP rainfall: damages per OSM road segment\n",
    "ead_df['ead_1000_binned'] = pd.cut(ead_df['ead_1000'],[0,1e3,1e4,2.5e4,ead_df['ead_1000'].max()],labels=['\\\\$1-$1,000','\\\\$1,000-$10,000','\\\\$10,000-$25,000','> $25,000'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='ead_1000_binned',cmap='Reds',legend=True,ax=ax)\n",
    "#damage_df.plot(column ='Partial destruction (0.5)',cmap='Reds',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1246500-9da8-4791-ac2a-7d8af1199a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD due to rainfall-triggered landslide events due to 25 year RP rainfall: damages per OSM road segment\n",
    "ead_df['ead_25_binned'] = pd.cut(ead_df['ead_25'],[0,1e3,1e4,2.5e4,ead_df['ead_1000'].max()],labels=['\\\\$1-$1,000','\\\\$1,000-$10,000','\\\\$10,000-$25,000','> $25,000'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='ead_25_binned',cmap='Reds',legend=True,ax=ax)\n",
    "#damage_df.plot(column ='Partial destruction (0.5)',cmap='Reds',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb210a-0e99-4258-842a-39f132e2b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure EAD due to rainfall-triggered landslides: damages per OSM road segment\n",
    "ead_df['ead_binned'] = pd.cut(ead_df['ead'],[0,1e3,1e4,2.5e4,ead_df['ead'].max()],labels=['\\\\$1-$1,000','\\\\$1,000-$10,000','\\\\$10,000-$25,000','> $25,000'])\n",
    "ead_df = gpd.GeoDataFrame(ead_df, geometry='geometry') # Set the GeoDataFrame's geometry column\n",
    "ead_df = ead_df.to_crs(3857)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "subnational.dissolve('GID_0').plot(ax=ax,facecolor=\"none\",edgecolor='black')\n",
    "\n",
    "ead_df.plot(column ='ead_binned',cmap='Reds',legend=True,ax=ax)\n",
    "#damage_df.plot(column ='Partial destruction (0.5)',cmap='Reds',legend=True,ax=ax)\n",
    "\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron,alpha=0.5)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(figures_path /'landslide_rf_ssp585_EAD.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a809c130-b3b8-4d32-b310-725ff442266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project road of interest\n",
    "dangara_gulliston_ids = dangara_gulliston_ids = ['629623298', '588578885', '667337582', '32623282', '32623136']\n",
    "project_df = ead_df[ead_df['osm_id'].isin(dangara_gulliston_ids)]\n",
    "\n",
    "project_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f37f9-94a1-4dce-b3b2-1cbf8d57f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shapely.length(project_df['geometry'])/1000) # length of road segments in km\n",
    "print(sum(shapely.length(project_df['geometry'])/1000)) # total length of road segments in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0030df-4215-4dbe-847e-8190563a5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "damage = sum(project_df['ead'])\n",
    "affected_road = sum(project_df['ead_1000_overlay'])/1000\n",
    "number_of_landslides = sum(project_df['ead_1000_number_landslides'])\n",
    "road_segments_length = 22.976544 + 20.829034 + 10.498568\n",
    "\n",
    "print('The expected annual damage for Dangara-Gulliston road project, based on total length of project road: {:.2f} dollar per km'.format(damage/67.34681578690605))\n",
    "print('The expected annual damage for Dangara-Gulliston road project, based on length of affected OSM road segment: {:.2f} dollar per km'.format(damage/road_segments_length)) \n",
    "print('The expected annual damage for Dangara-Gulliston road project, based on length of affected road segment: {:.2f} dollar per km'.format(damage/affected_road)) \n",
    "print('The expected annual damage for Dangara-Gulliston road project per landslide event: {:.2f} dollar'.format(damage/number_of_landslides)) #shouldn't we divide by the average landslides per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de528040-879b-48e7-bb01-b2b9334e5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(project_df['ead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d4c88-b345-4a7e-8684-6237f1001aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(project_df['ead_1000_overlay'])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79753e36-7542-4fd7-82fd-1c331f1a5d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
